{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/douglasbouchet/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "import nltk\n",
    "import numpy as np\n",
    "from nlp_helper import *\n",
    "from nltk import pos_tag\n",
    "from gensim import models\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Phrases\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_moviedb_data()\n",
    "df_plots = df.copy()\n",
    "# keep only the overview and providers columns as we don't use others for NLP\n",
    "df_plots = df_plots[[\"overview\", \"providers\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview Analysis\n",
    "\n",
    "In this NLP exploration, we are mostly interested by the overview and providers fields.  \n",
    "Let's see if some movies don't contain overviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7 % of movies have no overview\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    The adventures of a female reporter in the 1890s.\n",
       "1    Just as Galeen and Wegener's Der Golem (1915) ...\n",
       "2    The first feature-length motion picture produc...\n",
       "3    Australian bushranger movie.  The first filmed...\n",
       "4    L. Frank Baum would appear in a white suit and...\n",
       "5                             Know what this is about?\n",
       "6                                                     \n",
       "7                             Know what this is about?\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Â print the percentage of movies with no overview\n",
    "nb_with_no_overview = len(df_plots[df_plots['overview'].isnull()])\n",
    "print(round(nb_with_no_overview / len(df_plots) * 100, 1), \"% of movies have no overview\")\n",
    "\n",
    "# replace the missing values with an empty string\n",
    "df_plots['overview'] = df_plots['overview'].fillna('')\n",
    "\n",
    "df_plots.head(8)['overview']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that some movies (5,7) contain a non empty overview, but which indicate that there is no overview for this movie.  \n",
    "We can replace them by empty overviews. However this replacement may not be exhaustive if some useless plots are not\n",
    "$\\\\$ \"Know what this is about?\" but something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 % of movies contain \"Know what this is about?\" as an overview\n"
     ]
    }
   ],
   "source": [
    "# compute percentage of movies with overview \"Know what this is about\"\n",
    "print(round(len(df_plots[df_plots['overview'].str.contains('about')]['overview'])/len(df_plots),2)*100,\\\n",
    "     \"% of movies contain \\\"Know what this is about?\\\" as an overview\")\n",
    "# we can replace them with an empty string\n",
    "df_plots['overview'] = df_plots['overview'].str.replace('Know what this is about?','', regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, we have roughly 20% of movies without overview. This is tolerable given that our dataset is large, but firstly our search is not $\\\\$ exhaustive, and secondly we will have to check that most of the movies on the streaming platforms have an overview to be able to $\\\\$ apply NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to previous analysis, we decided to use providers of Switzerland and US, we will now see if the movies\n",
    "provided in these countries possess enough plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start by cleaning provider data\n",
    "df_plots['providers'] = df_plots['providers'].fillna('{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.0 % of movies in US have plots\n",
      "97.0 % of movies in CH have plots\n"
     ]
    }
   ],
   "source": [
    "# US provider movies\n",
    "df_plots_us = df_plots[df_plots['providers'].str.contains('US')]\n",
    "# UK provider movies\n",
    "df_plots_ch = df_plots[df_plots['providers'].str.contains('CH')]\n",
    "# keep only movies whom plots isn't empty   \n",
    "df_plots_us_overview = df_plots_us[df_plots_us['overview'] != '']\n",
    "# filter the providers from CH\n",
    "df_plots_ch_overview = df_plots_ch[df_plots_ch['overview'] != '']\n",
    "\n",
    "# print ratio of movies in US having plots\n",
    "print(round(len(df_plots_us_overview)/len(df_plots_us),2)*100, \"% of movies in US have plots\")\n",
    "# print ratio of movies in CH having plots\n",
    "print(round(len(df_plots_ch_overview)/len(df_plots_ch),2)*100, \"% of movies in CH have plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we can see that we can work on an NLP for topics analysis for the movies provided in US and CH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot preparation\n",
    "\n",
    "Now that we have seen we have enough movies plots in the US and CH regions, we can work on our topics analysis. $\\\\$\n",
    "To make a simple first exploration of topics analysis, we will simplify by merging movies from CH and US together $\\\\$\n",
    "as language is roughly the same. We could however try to split between the two in further analysis. \n",
    "\n",
    "We will transform the plots in order to make them intepretable by an LDA model. This includes\n",
    "- Tokenization\n",
    "- Lemmatization\n",
    "- Removing of stopwords\n",
    "\n",
    "This is usefull as we want to find ressemblance between words, so we should replace words with same meaning by one \n",
    "common word.  \n",
    "We also want to remove most commun words. This allows to remove low-information words, allowing our \n",
    "model to focus on important $\\\\$ words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep movie with overview and providers in US and CH\n",
    "df_plots = pd.concat([df_plots_us_overview, df_plots_ch_overview])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>providers</th>\n",
       "      <th>tokenized_plots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The fabled queen of Egypt's affair with Roman ...</td>\n",
       "      <td>{'AE': [], 'AG': [], 'BB': [], 'BH': [], 'BM':...</td>\n",
       "      <td>[The, fabled, queen, of, Egypt, 's, affair, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>The life of Jesus is played out in tableaux sh...</td>\n",
       "      <td>{'BR': ['Looke'], 'US': ['Amazon Prime Video',...</td>\n",
       "      <td>[The, life, of, Jesus, is, played, out, in, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>The women's suffrage movement inspired this si...</td>\n",
       "      <td>{'GB': [], 'US': []}</td>\n",
       "      <td>[The, women, 's, suffrage, movement, inspired,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>An army pilot is visiting the home of another ...</td>\n",
       "      <td>{'US': []}</td>\n",
       "      <td>[An, army, pilot, is, visiting, the, home, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>John Howard Payne leaves home and begins a car...</td>\n",
       "      <td>{'AE': [], 'AG': [], 'BB': [], 'BM': [], 'BS':...</td>\n",
       "      <td>[John, Howard, Payne, leaves, home, and, begin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              overview  \\\n",
       "41   The fabled queen of Egypt's affair with Roman ...   \n",
       "47   The life of Jesus is played out in tableaux sh...   \n",
       "85   The women's suffrage movement inspired this si...   \n",
       "105  An army pilot is visiting the home of another ...   \n",
       "108  John Howard Payne leaves home and begins a car...   \n",
       "\n",
       "                                             providers  \\\n",
       "41   {'AE': [], 'AG': [], 'BB': [], 'BH': [], 'BM':...   \n",
       "47   {'BR': ['Looke'], 'US': ['Amazon Prime Video',...   \n",
       "85                                {'GB': [], 'US': []}   \n",
       "105                                         {'US': []}   \n",
       "108  {'AE': [], 'AG': [], 'BB': [], 'BM': [], 'BS':...   \n",
       "\n",
       "                                       tokenized_plots  \n",
       "41   [The, fabled, queen, of, Egypt, 's, affair, wi...  \n",
       "47   [The, life, of, Jesus, is, played, out, in, ta...  \n",
       "85   [The, women, 's, suffrage, movement, inspired,...  \n",
       "105  [An, army, pilot, is, visiting, the, home, of,...  \n",
       "108  [John, Howard, Payne, leaves, home, and, begin...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the plots\n",
    "df_plots['tokenized_plots'] = df_plots['overview'].apply(\n",
    "    lambda movie_plot: word_tokenize(movie_plot))\n",
    "df_plots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "\n",
    "we start by assocating a POS tag to each word (i.e if a word is a Noun, Verb, Adjective, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     [(The, DT), (fabled, JJ), (queen, NN), (of, IN...\n",
       "47     [(The, DT), (life, NN), (of, IN), (Jesus, NNP)...\n",
       "85     [(The, DT), (women, NNS), ('s, POS), (suffrage...\n",
       "105    [(An, DT), (army, NN), (pilot, NN), (is, VBZ),...\n",
       "108    [(John, NNP), (Howard, NNP), (Payne, NNP), (le...\n",
       "Name: plots_with_POS_tag, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plots['plots_with_POS_tag'] = df_plots['tokenized_plots'].apply(\n",
    "    lambda tokenized_plot: pos_tag(tokenized_plot))\n",
    "df_plots['plots_with_POS_tag'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a word has no tag we don't change it. However if there is a tag, we lemmatize the word according to its tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     [The, fabled, queen, of, Egypt, 's, affair, wi...\n",
       "47     [The, life, of, Jesus, be, play, out, in, tabl...\n",
       "85     [The, woman, 's, suffrage, movement, inspire, ...\n",
       "105    [An, army, pilot, be, visit, the, home, of, an...\n",
       "108    [John, Howard, Payne, leave, home, and, begin,...\n",
       "Name: lemmatized_plots, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# Now we can lemmatize each word, given its POS tag\n",
    "df_plots['lemmatized_plots'] = df_plots['plots_with_POS_tag'].apply(\n",
    "    lambda tokenized_plot: [word[0] if get_wordnet_pos(word[1]) == ''\\\n",
    "        else lemmatizer.lemmatize(word[0], get_wordnet_pos(word[1])) for word in tokenized_plot])\n",
    "df_plots['lemmatized_plots'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â TODO list of stop words may be improved\n",
    "# create our list of stopwords\n",
    "stop_words = ['\\'s']\n",
    "all_stopwords = stopwords.words('English') + list(string.punctuation) + stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    [fabled, queen, egypt, affair, roman, general,...\n",
       "47       [life, jesus, play, tableau, shot, holy, land]\n",
       "Name: plots_without_stopwords, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# remove the white space inside each words\n",
    "df_plots['plots_without_stopwords'] = df_plots['lemmatized_plots'].apply(\n",
    "    lambda tokenized_plot: [word.strip() for word in tokenized_plot])\n",
    "# lowercase all words in each plot\n",
    "df_plots['plots_without_stopwords'] = df_plots['plots_without_stopwords'].apply(\n",
    "    lambda plot: [word.lower() for word in plot])\n",
    "# remove stopwords from the plots\n",
    "df_plots['plots_without_stopwords'] = df_plots['plots_without_stopwords'].apply(\n",
    "    lambda plot: [word for word in plot if word not in all_stopwords])\n",
    "# remove word if contains other letter than a-z or is a single character\n",
    "df_plots['plots_without_stopwords'] = df_plots['plots_without_stopwords'].apply(\n",
    "    lambda plot: [word for word in plot if word.isalpha() and len(word) > 1])\n",
    "df_plots['plots_without_stopwords'].head()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We kept 49.0% of the words in the corpus\n"
     ]
    }
   ],
   "source": [
    "before_stop_words_total_number_of_words =\\\n",
    "     len([word for sentence in df_plots['lemmatized_plots'] for word in sentence])\n",
    "after_stop_words_total_number_of_words =\\\n",
    "     len([word for sentence in df_plots['plots_without_stopwords'] for word in sentence])\n",
    "print(\"We kept {}% of the words in the corpus\".format(\\\n",
    "    round(after_stop_words_total_number_of_words/before_stop_words_total_number_of_words, 2) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Direchlet Allocation\n",
    "\n",
    "We need to create a list of tokens, i.e words that will be used inside our dictionary (depending on their frequency). \n",
    "$\\\\$\n",
    "We can start by creating bi-gram for some words (represent to one words by one unique composed word)  \n",
    "It can be also interesting to see if creating tri-gram allows to extract more information from plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fabled', 'queen', 'egypt', 'affair', 'roman', 'general', 'marc', 'antony', 'ultimately', 'disastrous'], ['life', 'jesus', 'play', 'tableau', 'shot', 'holy_land']]\n"
     ]
    }
   ],
   "source": [
    "tokens = df_plots['plots_without_stopwords'].tolist()\n",
    "bigram_model = Phrases(tokens)\n",
    "tokens = list(bigram_model[tokens])\n",
    "print(tokens[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_below = 60 # minimum number of documents a word must be present in to be kept\n",
    "no_above = 0.5 # maximum proportion of documents a word can be present in to be kept\n",
    "n_topics = 10 # number of topics\n",
    "n_passes = 10 # number of passes through the corpus during training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnary & Corpus\n",
    "\n",
    "The dictionnary will be the list of unique words, and the corpus a list of movie plots bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 6021\n",
      "Dictionary first 10 elements: [(0, 'affair'), (1, 'disastrous'), (2, 'egypt'), (3, 'fabled'), (4, 'general'), (5, 'marc'), (6, 'queen'), (7, 'roman'), (8, 'ultimately'), (9, 'jesus')]\n",
      "Corpus size: 117628\n",
      "Corpus first 2 elements: [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)], [(9, 1), (10, 1), (11, 1), (12, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# we create a dictionary that maps each word to a unique integer\n",
    "# we also create a corpus. Each movie plot is encoded as a bag of words in the corpus. \n",
    "# A bag of word means that we count the number of times each word appears in the mvoie plot\n",
    "dictionary,corpus = build_dictionnary_and_corpus(tokens, no_below=no_below, no_above=no_above)\n",
    "print(\"Dictionary size: {}\".format(len(dictionary)))\n",
    "print(\"Dictionary first 10 elements: {}\".format(list(dictionary.items())[0:10]))\n",
    "print(\"Corpus size: {}\".format(len(corpus)))\n",
    "print(\"Corpus first 2 elements: {}\".format(corpus[0:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9999)\n",
    "lda_model = create_lda_model(corpus, dictionary, num_topics=n_topics, passes=n_passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: story relationship village last behind power grow best stop today\n",
      "Topic 1: family love woman man father mother meet turn girl son\n",
      "Topic 2: film people group use escape artist personal land join yet\n",
      "Topic 3: look mysterious call travel couple create around mission memory visit\n",
      "Topic 4: world help fight struggle save order break future legendary friendship\n",
      "Topic 5: one young face boy school move murder night never event\n",
      "Topic 6: life find new two take become get make live go\n",
      "Topic 7: friend also show experience country even real share job close\n",
      "Topic 8: year journey lead documentary change past secret history tell war\n",
      "Topic 9: set day start begin together back dream brother great place\n"
     ]
    }
   ],
   "source": [
    "# get the topics \n",
    "topics = get_topics(lda_model, num_topics=n_topics, num_words=10)\n",
    "# print topics with new line\n",
    "for i,topic in enumerate(topics):\n",
    "    print(\"Topic {}: {}\".format(i,topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each movie plot, get its topic distribution (i.e the probability of each topic) in descending order\n",
    "topic_distributions = get_topic_distribution(lda_model, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie plot: The fabled queen of Egypt's affair with Roman general Marc Antony is ultimately disastrous for both of them.\n",
      "Topic distribution for the first movie plot: [(1, 0.2051123), (6, 0.19737302), (9, 0.10735431), (5, 0.10006276), (8, 0.0899757), (4, 0.06919074), (3, 0.068079986), (2, 0.06262633), (0, 0.05182138), (7, 0.04840347)]\n"
     ]
    }
   ],
   "source": [
    "# print first movie plot \n",
    "print(\"Movie plot: {}\".format(df_plots['overview'].iloc[0]))\n",
    "print(\"Topic distribution for the first movie plot: {}\".format(topic_distributions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO add analysis + tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd36d5f1320431a45e01240dcc8ffb6ab490925b08bbe6d8a89832130106a873"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
